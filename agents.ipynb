{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepration\n",
    "\n",
    "Loading env variables and vectorDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Laden Sie die Umgebungsvariablen aus der .env-Datei\n",
    "load_dotenv()\n",
    "API_KEY = os.environ.get(\"API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"vectorstore.pkl\", \"rb\") as f:\n",
    "    vectorstore = pickle.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agents\n",
    "\n",
    "Agenten verwenden ein LLM, um zu bestimmen, welche Aktionen in welcher Reihenfolge durchgeführt werden sollen. Eine Aktion kann entweder die Verwendung eines Werkzeugs und die Beobachtung seiner Ausgabe oder die Rückgabe an den Benutzer sein. Für die Verwendung eines Agent ist es wichtig neben dem Konzept eines LLM, ein neues Konzept und das eines \"Tools\" zu verstehen."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "Werkzeuge sind Funktionen, die Agenten nutzen können, um mit der Welt zu interagieren. Diese Werkzeuge können allgemeine Dienstprogramme (z. B. Suche), andere Ketten oder sogar andere Agenten sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm=OpenAI(model_name=\"text-davinci-003\", temperature=0.7, openai_api_key=API_KEY)\n",
    "\n",
    "tool_names = [\"llm-math\"]\n",
    "tools = load_tools(tool_names, llm=llm)\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "tool_list = [\n",
    "    Tool(\n",
    "        name = \"Math Tool\",\n",
    "        func=tools[0].run,\n",
    "        description=\"Tool to calculate, nothing else\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "\n",
    "agent = initialize_agent(tool_list, \n",
    "                         llm, \n",
    "                         agent=\"zero-shot-react-description\", \n",
    "                         verbose=True)\n",
    "agent.run(\"Wie geht es dir?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(\"Was ist 100 geteilt durch 25?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Tools\n",
    "\n",
    "Man kann auch eigene Tools erstellen indem man eine Klasse erstellt, die von BaseTool erbt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.callbacks.manager import AsyncCallbackManagerForToolRun, CallbackManagerForToolRun\n",
    "\n",
    "class CustomSearchTool(BaseTool):\n",
    "    name = \"custom_search\"\n",
    "    description = \"useful for when you need to answer questions about current events\"\n",
    "\n",
    "    def _run(self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None) -> str:\n",
    "        store = vectorstore.as_retriever()\n",
    "        docs = store.get_relevant_documents(query)\n",
    "        text_list = [doc.page_content for doc in docs]\n",
    "        return \"\\n\".join(text_list)\n",
    "    \n",
    "    async def _arun(self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"custom_search does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType\n",
    "\n",
    "tools = [CustomSearchTool()]\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(\"Was ist ein Huninchen?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
